{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "In this notebook, I'll train an agent to solve the Reacher Environment using Unity ML-Agents.\n",
    "\n",
    "---\n",
    "\n",
    "# Index\n",
    "\n",
    "- []()\n",
    "- []()\n",
    "- []()\n",
    "- []()\n",
    "- []()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup the Environment\n",
    "\n",
    "<img align=\"left\" width=\"150\" src=\"https://www.nclouds.com/img/services/toolkit/sagemaker.png\"/>\n",
    "\n",
    "This notebook was developed on AWS SageMaker.\n",
    "\n",
    "The kernel used is **conda_python3**\n",
    "\n",
    "To setup this environment on SageMaker you need to run the next 3 cells.\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch===1.5.1 torchvision===0.6.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "from agent import Agent\n",
    "\n",
    "# One agent\n",
    "#env_path = \"one_agent/Reacher_Windows_x86_64/Reacher.exe\"\n",
    "#env_path = \"one_agent/Reacher_Linux/Reacher.x86_64\"\n",
    "\n",
    "# Multi agent\n",
    "#env_path = \"multi_agent/Reacher_Windows_x86_64/Reacher.exe\"\n",
    "env_path = \"multi_agent/Reacher_Linux/Reacher.x86_64\"\n",
    "\n",
    "env = UnityEnvironment(file_name=env_path, no_graphics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define helper functions to training session\n",
    "\n",
    "Here we'll create a function that can be very helpful to teach the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_trainer(agents, n_episodes=2000, max_time_step=None, score_deque=100, print_range=10, early_stop=30, add_noise=False, save_model=True, verbose=False):\n",
    "    \"\"\"Deep Q-Learning trainer.\n",
    "    Params\n",
    "    ======\n",
    "        agents (list): List of Agent Objects\n",
    "        n_episodes (int): maximum number of training episodes.\n",
    "        max_time_step (int or None): The max time step per episode, if None, the agent will training until environment is done.\n",
    "        scores_deque (int): The len of score deque.\n",
    "        print_range (int): range to print partials results.\n",
    "        early_stop (int): Stop training when achieve a defined score respecting 10 min n_episodes.\n",
    "        add_noise (bool): If True, we'll reset at each step and add_noise at each action call.\n",
    "        save_model (bool): If True, we'll save the model weights when we solve the environment\n",
    "        verbose (bool): If verbose true, we'll print some infos on console.\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=score_deque)\n",
    "    scores = np.zeros(num_agents)\n",
    "    scores_episode = []\n",
    "    \n",
    "    for ep in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.zeros(num_agents)\n",
    "        time_step = 0\n",
    "        training = True\n",
    "        \n",
    "        if add_noise:\n",
    "            for agent in agents:\n",
    "                agent.reset()\n",
    "\n",
    "        while training:\n",
    "            actions = np.array([agents[i].act(states[i], add_noise) for i in range(num_agents)])\n",
    "            env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "            next_states = env_info.vector_observations     # get the next state\n",
    "            rewards = env_info.rewards                     # get the reward\n",
    "            dones = env_info.local_done        \n",
    "            \n",
    "            for i in range(num_agents):\n",
    "                agents[i].step(states[i], actions[i], rewards[i], next_states[i], dones[i]) \n",
    " \n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            time_step += 1\n",
    "            \n",
    "            if isinstance(max_time_step, (int, float)):\n",
    "                if time_step >= max_time_step:\n",
    "                    training = False\n",
    "                    \n",
    "            if np.any(dones):\n",
    "                break \n",
    "                \n",
    "        score = np.mean(scores)\n",
    "        scores_window.append(score)\n",
    "        scores_episode.append(score)\n",
    "\n",
    "        if verbose:\n",
    "            print('\\rEpisode {} || Avg Score: {:.2f} || Max Score: {:.2f} || Avg Score (last {} episodes): {:.2f}'.format(ep, score, np.max(scores), score_deque, np.mean(scores_window)), end=\"\")\n",
    "            if ep % print_range == 0:\n",
    "                print('\\rEpisode {} || Avg Score: {:.2f} || Max Score: {:.2f} || Avg Score (last {} episodes): {:.2f}'.format(ep, score, np.max(scores), score_deque, np.mean(scores_window)))\n",
    "        if np.mean(scores_window) >= early_stop:\n",
    "            if verbose:\n",
    "                print('\\nEnvironment solved in {:d} episodes! || Avg Score: {:.2f}'.format(ep, np.mean(scores_window)))\n",
    "            if save_model:\n",
    "                Agent.save_model(params=agents[0].get_params())\n",
    "                \n",
    "            break\n",
    "            \n",
    "    return scores_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Agent\n",
    "\n",
    "In the next code cells, we will train the Agent to work on environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 || Avg Score: 0.37 || Max Score: 1.20 || Avg Score (last 100 episodes): 0.37\n",
      "Episode 2 || Avg Score: 0.80 || Max Score: 1.77 || Avg Score (last 100 episodes): 0.58\n",
      "Episode 3 || Avg Score: 2.33 || Max Score: 3.88 || Avg Score (last 100 episodes): 1.17\n",
      "Episode 4 || Avg Score: 3.43 || Max Score: 6.15 || Avg Score (last 100 episodes): 1.73\n",
      "Episode 5 || Avg Score: 4.31 || Max Score: 7.84 || Avg Score (last 100 episodes): 2.25\n",
      "Episode 6 || Avg Score: 6.13 || Max Score: 10.40 || Avg Score (last 100 episodes): 2.90\n",
      "Episode 7 || Avg Score: 6.73 || Max Score: 10.53 || Avg Score (last 100 episodes): 3.44\n",
      "Episode 8 || Avg Score: 8.00 || Max Score: 11.82 || Avg Score (last 100 episodes): 4.01\n",
      "Episode 9 || Avg Score: 9.05 || Max Score: 14.33 || Avg Score (last 100 episodes): 4.57\n",
      "Episode 10 || Avg Score: 11.79 || Max Score: 29.48 || Avg Score (last 100 episodes): 5.29\n",
      "Episode 11 || Avg Score: 13.19 || Max Score: 20.14 || Avg Score (last 100 episodes): 6.01\n",
      "Episode 12 || Avg Score: 13.76 || Max Score: 18.80 || Avg Score (last 100 episodes): 6.66\n",
      "Episode 13 || Avg Score: 17.47 || Max Score: 24.53 || Avg Score (last 100 episodes): 7.49\n",
      "Episode 14 || Avg Score: 18.96 || Max Score: 24.27 || Avg Score (last 100 episodes): 8.31\n",
      "Episode 15 || Avg Score: 23.30 || Max Score: 31.36 || Avg Score (last 100 episodes): 9.31\n",
      "Episode 20 || Avg Score: 31.99 || Max Score: 39.50 || Avg Score (last 100 episodes): 14.39\n",
      "Episode 21 || Avg Score: 35.76 || Max Score: 39.46 || Avg Score (last 100 episodes): 15.41\n",
      "Episode 22 || Avg Score: 37.75 || Max Score: 39.62 || Avg Score (last 100 episodes): 16.42\n",
      "Episode 23 || Avg Score: 38.04 || Max Score: 39.56 || Avg Score (last 100 episodes): 17.36\n",
      "Episode 24 || Avg Score: 37.25 || Max Score: 39.33 || Avg Score (last 100 episodes): 18.19\n",
      "Episode 25 || Avg Score: 37.52 || Max Score: 39.64 || Avg Score (last 100 episodes): 18.96\n",
      "Episode 26 || Avg Score: 38.12 || Max Score: 39.65 || Avg Score (last 100 episodes): 19.70\n",
      "Episode 27 || Avg Score: 39.02 || Max Score: 39.62 || Avg Score (last 100 episodes): 20.42\n",
      "Episode 28 || Avg Score: 38.77 || Max Score: 39.61 || Avg Score (last 100 episodes): 21.07\n",
      "Episode 29 || Avg Score: 39.31 || Max Score: 39.66 || Avg Score (last 100 episodes): 21.70\n",
      "Episode 30 || Avg Score: 39.07 || Max Score: 39.61 || Avg Score (last 100 episodes): 22.28\n",
      "Episode 31 || Avg Score: 39.04 || Max Score: 39.55 || Avg Score (last 100 episodes): 22.82\n",
      "Episode 32 || Avg Score: 38.98 || Max Score: 39.59 || Avg Score (last 100 episodes): 23.32\n",
      "Episode 33 || Avg Score: 39.25 || Max Score: 39.66 || Avg Score (last 100 episodes): 23.81\n",
      "Episode 34 || Avg Score: 39.23 || Max Score: 39.66 || Avg Score (last 100 episodes): 24.26\n",
      "Episode 35 || Avg Score: 38.26 || Max Score: 39.55 || Avg Score (last 100 episodes): 24.66\n",
      "Episode 36 || Avg Score: 39.21 || Max Score: 39.65 || Avg Score (last 100 episodes): 25.06\n",
      "Episode 37 || Avg Score: 39.24 || Max Score: 39.67 || Avg Score (last 100 episodes): 25.45\n",
      "Episode 38 || Avg Score: 38.53 || Max Score: 39.61 || Avg Score (last 100 episodes): 25.79\n",
      "Episode 39 || Avg Score: 39.43 || Max Score: 39.65 || Avg Score (last 100 episodes): 26.14\n",
      "Episode 40 || Avg Score: 39.47 || Max Score: 39.65 || Avg Score (last 100 episodes): 26.47\n",
      "Episode 41 || Avg Score: 39.29 || Max Score: 39.64 || Avg Score (last 100 episodes): 26.79\n",
      "Episode 42 || Avg Score: 38.06 || Max Score: 39.64 || Avg Score (last 100 episodes): 27.06\n",
      "Episode 43 || Avg Score: 39.31 || Max Score: 39.63 || Avg Score (last 100 episodes): 27.34\n",
      "Episode 44 || Avg Score: 38.81 || Max Score: 39.55 || Avg Score (last 100 episodes): 27.60\n",
      "Episode 45 || Avg Score: 38.69 || Max Score: 39.64 || Avg Score (last 100 episodes): 27.85\n",
      "Episode 46 || Avg Score: 38.88 || Max Score: 39.68 || Avg Score (last 100 episodes): 28.09\n",
      "Episode 47 || Avg Score: 39.22 || Max Score: 39.63 || Avg Score (last 100 episodes): 28.32\n",
      "Episode 48 || Avg Score: 39.03 || Max Score: 39.65 || Avg Score (last 100 episodes): 28.55\n",
      "Episode 49 || Avg Score: 39.10 || Max Score: 39.64 || Avg Score (last 100 episodes): 28.76\n",
      "Episode 50 || Avg Score: 39.37 || Max Score: 39.61 || Avg Score (last 100 episodes): 28.98\n",
      "Episode 51 || Avg Score: 39.26 || Max Score: 39.59 || Avg Score (last 100 episodes): 29.18\n",
      "Episode 52 || Avg Score: 38.36 || Max Score: 39.66 || Avg Score (last 100 episodes): 29.35\n",
      "Episode 53 || Avg Score: 39.34 || Max Score: 39.62 || Avg Score (last 100 episodes): 29.54\n",
      "Episode 54 || Avg Score: 39.39 || Max Score: 39.64 || Avg Score (last 100 episodes): 29.72\n",
      "Episode 55 || Avg Score: 39.28 || Max Score: 39.68 || Avg Score (last 100 episodes): 29.90\n",
      "Episode 56 || Avg Score: 39.39 || Max Score: 39.68 || Avg Score (last 100 episodes): 30.07\n",
      "\n",
      "Environment solved in 56 episodes! || Avg Score: 30.07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 4h 42min 2s, sys: 1h 22min 31s, total: 1d 6h 4min 33s\n",
      "Wall time: 1h 58min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "agents = [] \n",
    "for i in range(num_agents):\n",
    "    agents.append(Agent(state_size=state_size, action_size=action_size, random_seed=399, memory_size=int(1e6),\n",
    "                        batch_size=16, gamma=0.99, tau=1e-3, lr_actor=1e-4, lr_critic=1e-4, weight_decay=0.0,\n",
    "                        actor_units=(256, 128), critic_units=(256, 128), action_min=-1, action_max=1))\n",
    "    \n",
    "scores = rl_trainer(agents, n_episodes=2000, print_range=1, early_stop=30,\n",
    "                    add_noise=False, save_model=True, verbose=True)\n",
    "\n",
    "agent = agents[0]\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.load_model()\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Agent on Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0\n",
    "\n",
    "while True:\n",
    "    action = agent.act(state)\n",
    "    env_info = env.step(action)[brain_name]\n",
    "    next_state = env_info.vector_observations[0]\n",
    "    reward = env_info.rewards[0]\n",
    "    done = env_info.local_done[0]\n",
    "    score += reward\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
